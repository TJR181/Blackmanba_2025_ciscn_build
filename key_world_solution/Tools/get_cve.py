import os
import requests
import re
import time
import concurrent.futures
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from tqdm import tqdm


def requests_retry_session(
    retries=3,
    backoff_factor=1,
    status_forcelist=(500, 502, 503, 504),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        connect=retries,
        read=retries,
        status=retries,
        backoff_factor=backoff_factor,
        allowed_methods=["GET", "POST"],
        status_forcelist=status_forcelist,
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


def get_cve_ids(keyword, start_year, end_year, sleep_seconds=5):
    url = f"https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword={keyword}"
    headers = {"User-Agent": "Mozilla/5.0"}
    session = requests_retry_session()

    try:
        response = session.get(url, headers=headers, timeout=(10, 20))
        response.raise_for_status()
    except Exception as e:
        print(f"‚ùå ËØ∑Ê±ÇÂ§±Ë¥• [{keyword}]Ôºö{e}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")

    cve_pattern = re.compile(r"CVE-(\d{4})-\d+")
    cve_ids = set()

    for link in soup.find_all("a", href=True):
        text = link.text.strip()
        match = cve_pattern.match(text)
        if match:
            year = int(match.group(1))
            if start_year <= year <= end_year:
                cve_ids.add(text)

    print(f"‚úÖ [{keyword}] ÂÖ±ÂèëÁé∞ {len(cve_ids)} Êù° CVE")
    time.sleep(sleep_seconds)
    return sorted(cve_ids, reverse=True)


def get_and_save_cve_ids(
    device_type, keyword, start_year, end_year, output_dir="./data", max_workers=4
):
    filename = f"{device_type}_{keyword}.txt"
    filepath = os.path.join(output_dir, filename)

    if os.path.exists(filepath):
        print(f"‚ö†Ô∏è Êñá‰ª∂Â∑≤Â≠òÂú®ÔºåË∑≥ËøáÁà¨ÂèñÔºö{filepath}")
        return

    print(f"\nüîç Ê≠£Âú®ËØ∑Ê±Ç CVE ID È°µÈù¢ [{keyword}]...")
    cves = get_cve_ids(keyword, start_year, end_year)
    if not cves:
        print(f"‚ö†Ô∏è Ê≤°ÊúâÊâæÂà∞Á¨¶ÂêàÊù°‰ª∂ÁöÑ CVE ÁºñÂè∑Ôºö{device_type}_{keyword}")
        return

    os.makedirs(output_dir, exist_ok=True)

    print(f"üìÑ Ê≠£Âú®‰øùÂ≠ò {device_type}_{keyword} ÂÖ± {len(cves)} Êù° CVE ...")
    failed = []

    def validate(cve):
        if re.match(r"CVE-\d{4}-\d+", cve):
            return cve
        else:
            failed.append(cve)
            return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(
            tqdm(
                executor.map(validate, cves),
                total=len(cves),
                desc=f"üì• È™åËØÅ {device_type}/{keyword}",
                ncols=100,
            )
        )

    valid_cves = [cve for cve in results if cve]

    with open(filepath, "w", encoding="utf-8") as f:
        for idx, cve in enumerate(valid_cves, start=1):
            f.write(cve + "\n")

    print(f"\n‚úÖ ÊàêÂäüÂÜôÂÖ• {len(valid_cves)} Êù° CVE Âà∞ {filepath}")
    if failed:
        print(f"‚ùå Êúâ {len(failed)} Êù°Êó†Êïà CVE ÁºñÂè∑Êú™ÂÜôÂÖ•Ôºö{failed}")
